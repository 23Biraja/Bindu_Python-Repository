{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d_mETXD3suaI"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer=LancasterStemmer()\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AO_jMbxx7xkk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "#warnings.simplifilter('ignore')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('Database JNU.txt', 'r' , errors = 'ignore')\n",
    "doc_bindu=f.read() \n",
    "doc_bindu=doc_bindu.lower()\n",
    "sent_tokens = nltk.sent_tokenize(doc_bindu)\n",
    "word_tokens = nltk.word_tokenize(doc_bindu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "84mhDbL780df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jnu( jawaharlal nehru university): \\n\\nhistory of jnu:\\nthe jawaharlal nehru university constituted under the jawaharlal nehru university act 1966, (53 of 1966) came into existence in\\n1969. its objectives, as defined in the first schedule of the act, are as follows:\"the university shall endeavour to promote the principles for which jawaharlal nehru worked during his life-time, national integration,social justice, secularism, democratic way of life, international understanding and scientific approach to the problems of society,for more details , visit the jnu website : https://www.jnu.ac.in .',\n",
       " 'schools in jnu:\\n(i)school of international studies\\n(ii) school of language, literature and culture studies\\n(iii) school of social sciences\\n(iv) school of arts and aesthetics\\n(v) school of life sciences\\n(vi) school of environmental sciences\\n(vii) school of computer and systems sciences\\n(viii) school of physical sciences\\n(ix) school of computational and integrative sciences\\n(x) school of biotechnology\\n(xi) school of sanskrit and indic studies\\n(xii) school of engineering\\n(xiii) atal bihari vajpayee school of management and entrepreneurship\\n(xiv) school of indian traditional music and dance\\n(xv) special centre for e-learning\\n(xvi) special centre for molecular medicine\\n(xvii) special centre for the study of law and governance\\n(xviii) special centre for nano sciences\\n(xix) special centre for disaster research\\n(xx) special centre for the study of north east india\\n(xxi) special centre for national security studies\\n(xxii) special centre for systems medicine \\n for more details , visit the jnu website : https://www.jnu.ac.in  .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jnu', '(', 'jawaharlal', 'nehru']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eGlSBVH5k1v5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"didn't\", 'above', 'will', 'few', 'shan', 'they', 'his', 'is', 'with', 'then', 'how', 'which', 'do', 'was', 'couldn', 'theirs', 'him', \"should've\", 'by', 'wasn', 'both', 'each', 't', 'can', \"haven't\", 'of', 'again', 'your', 'he', 'she', 'because', 'them', 'i', 'and', \"hasn't\", 'hers', 'over', 'ain', 'as', \"weren't\", \"you'd\", 'too', 'don', 'himself', 'until', 'below', 'ma', 'aren', 'its', 'on', 'ourselves', \"couldn't\", 'very', 'all', \"won't\", \"that'll\", 'been', 'themselves', 'o', \"you'll\", 'me', \"you've\", 're', 'an', 'more', \"needn't\", 'myself', 'or', 'under', 'now', \"aren't\", 'ours', 'some', 'yourselves', \"mustn't\", \"wasn't\", 'whom', 'were', 'what', 'hasn', \"she's\", \"shouldn't\", 'shouldn', 'other', 'there', 'further', 'those', 'when', 'their', 'my', 'own', 'if', 'just', 'a', 'had', 'doing', 'll', 'but', 'are', 'did', 'once', 'than', 'from', 'won', \"you're\", 'isn', 'has', 'itself', 'having', 'why', 'up', 'such', 's', 'mightn', 'who', 'our', 'between', 'at', 'most', 'yourself', 'only', \"it's\", 'same', \"wouldn't\", 'wouldn', \"shan't\", 'no', 'm', 'd', 'needn', 'during', 'does', 'off', 'to', 'out', 'weren', 'should', 'any', 'being', \"doesn't\", 'didn', 'for', 'be', \"isn't\", 'mustn', 'this', 'have', 'against', 'after', 'you', 'before', 'where', 'about', 'y', 'haven', 'her', 'down', 'we', 'it', 'while', 'in', \"don't\", 'that', 'nor', \"hadn't\", 'through', 'these', 'yours', 'so', 'the', 'doesn', 'here', 'into', 'not', 'am', 'hadn', 've', 'herself', \"mightn't\"}\n",
      "['/content/DatabaseJNU']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "text=\"/content/DatabaseJNU\"\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "tokenized_words = word_tokenize(text)\n",
    "tokenize_words_without_stop_words = []\n",
    "for word in tokenized_words:\n",
    "  if word not in stop_words:\n",
    "    tokenize_words_without_stop_words.append(word)\n",
    "print(tokenize_words_without_stop_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "y94LQbT99iT4"
   },
   "outputs": [],
   "source": [
    "lemm = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemm.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cP9cMmgj9luR"
   },
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",\"what's up\")\n",
    "#GREETING_INPUTS = set(key_word)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\",\"please ask\",\"ask dear\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "def greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a2pvqR3Lu-GO"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HBD3gwlu4bZK"
   },
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "  bindu_response=''\n",
    "  TfidVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "  tfidf = TfidVec.fit_transform(sent_tokens)\n",
    "  vals= cosine_similarity(tfidf[-1], tfidf)\n",
    "  idx=vals.argsort()[0][-2]\n",
    "  flat= vals.flatten()\n",
    "  flat.sort()\n",
    "  req_tfidf = flat[-2]\n",
    "  if(req_tfidf==0):\n",
    "    bindu_response=bindu_response+\" I am sorry,I am not getting,please do a google search\" + \"and visit https://www.jnu.ac.in/\"\n",
    "    return bindu_response  \n",
    "  else:\n",
    "     bindu_response = bindu_response+sent_tokens[idx]\n",
    "     return bindu_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ig3p5DGuBtcZ"
   },
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "nltk.download('stopwords', quiet=True, raise_on_error=True)\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "tokenized_stop_words = nltk.word_tokenize(' '.join(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        nltk.download('punkt', quiet=True, raise_on_error=True)\n",
    "        self.stemmer = nltk.stem.PorterStemmer()\n",
    "        \n",
    "    def _stem(self, token):\n",
    "        if (token in stop_words):\n",
    "            return token  # Solves error \"UserWarning: Your stop_words may be inconsistent with your preprocessing.\"\n",
    "        return self.stemmer.stem(token)\n",
    "        \n",
    "    def __call__(self, line):\n",
    "        tokens = nltk.word_tokenize(line)\n",
    "        tokens = (self._stem(token) for token in tokens)  # Stemming\n",
    "        return list(tokens)\n",
    "    \n",
    "tokenizer = CountVectorizer(min_df=5, \n",
    "                            ngram_range=(1, 2),\n",
    "                            tokenizer=Tokenizer(),\n",
    "                            stop_words=tokenized_stop_words,\n",
    "                            lowercase=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxdOzDdR-NLM",
    "outputId": "d2d2cf45-3c0d-481b-d794-6f80d8fad40c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinduBot:Hello!! I'm Bindu,specifically designed to answer some basic queries about JNU.,if you wanna exit any time,type Bye!\n",
      "hi\n",
      "\n",
      " BinduBot:  I am glad! You are talking to me\n",
      "\n",
      "tell me the history of jnu\n",
      "\n",
      " BinduBot: \n",
      "  jnu( jawaharlal nehru university): \n",
      "\n",
      "history of jnu:\n",
      "the jawaharlal nehru university constituted under the jawaharlal nehru university act 1966, (53 of 1966) came into existence in\n",
      "1969. its objectives, as defined in the first schedule of the act, are as follows:\"the university shall endeavour to promote the principles for which jawaharlal nehru worked during his life-time, national integration,social justice, secularism, democratic way of life, international understanding and scientific approach to the problems of society,for more details , visit the jnu website : https://www.jnu.ac.in . \n",
      "\n",
      "fee structure of jnu\n",
      "\n",
      " BinduBot: \n",
      "  fee and mode of payment:\n",
      "tuition fee (annual) rs.216.00*** rs.120.00\n",
      "2 sports fee (annual) rs.16.50 rs.16.50\n",
      "3 literary & cultural fee (annual) rs.16.50 rs.16.50\n",
      "4 library fee (annual) rs.6.00 rs.6.00\n",
      "5 medical fee (annual) rs.9.00 ----\n",
      "6 medical booklet rs.12.00 ----\n",
      "7 students aid fund (annual) rs.4.50 ----\n",
      "8 *admission fee rs.5.00 rs.5.00\n",
      "9 *enrolment fee rs.5.00 rs.5.00\n",
      "10 *security deposit (refundable) rs.40.00 rs.40.00\n",
      "11 identity card folder rs.10.00 rs.10.00\n",
      "for more details , visit the jnu website : https://www.jnu.ac.in . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"BinduBot:Hello!! I'm Bindu,specifically designed to answer some basic queries about JNU.,if you wanna exit any time,type Bye!\")\n",
    "while(flag== True):\n",
    "  user_response = input()\n",
    "  user_response= user_response.lower()\n",
    "  if(user_response!='bye'):\n",
    "      if(user_response=='thanks' or user_response=='thank you'):\n",
    "        flag= False\n",
    "        print(\"BinduBot: you are welcome.. come again for more info\")\n",
    "      else:\n",
    "        if(greeting(user_response)!= None):\n",
    "          print(\"\\n BinduBot:  \"+greeting(user_response)+\"\\n\")\n",
    "          \n",
    "        else:\n",
    "               sent_tokens.append(user_response)\n",
    "               word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "               final_words=list(set(word_tokens))\n",
    "               print(\"\\n BinduBot:\",end=\" \")\n",
    "               print(\"\\n \",response(user_response),\"\\n\")\n",
    "               sent_tokens.remove(user_response)\n",
    "            \n",
    "  else: \n",
    "    flag= False\n",
    "    print(\"BinduBot:GoodBye ! Take Care\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BinduBot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
